{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Household composition and place of birth in Our Future Health\n",
    "\n",
    "## Purpose\n",
    "This notebook extracts participant-reported household composition and place-of-birth information from the Our Future Health (OFH) baseline questionnaire and summarises their distributions within the cohort.\n",
    "\n",
    "## Outputs\n",
    "- `outputs/intermediate/questionnaire_diag_fields_metadata.csv`  \n",
    "  Metadata describing questionnaire fields related to household size, household relatedness, and place of birth.\n",
    "- `outputs/raw/questionnaire_diag_fields_raw_values_query.sql`  \n",
    "  SQL query used to extract raw questionnaire responses.\n",
    "- In-memory summary tables reporting:\n",
    "  - Percentage distribution of household size categories\n",
    "  - Counts and proportions of household relatedness categories (including a derived “live alone” category)\n",
    "  - Counts and percentages of place-of-birth responses\n",
    "\n",
    "## Relationship to manuscript\n",
    "Results from this notebook are used to generate **Figure 2** in the main text, which describes the sociodemographic composition of the Our Future Health cohort.\n",
    "\n",
    "## Data and access notes\n",
    "Analyses use restricted Our Future Health data accessed within the OFH Trusted Research Environment under approved study permissions. Outputs are limited to aggregated, non-disclosive summary statistics, in accordance with OFH Safe Output requirements.\n",
    "\n",
    "## Notes\n",
    "Household size is binned into prespecified categories for reporting. Participants reporting a household size of one are classified as “live alone” in household relatedness summaries. Percentages for place of birth are calculated among participants providing non-missing responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import dxpy\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Local imports\n",
    "import phenofhy\n",
    "\n",
    "# Turn off logging\n",
    "import logging\n",
    "# logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Phenotype Analysis\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"128\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run using config-defined .CSV input file and output path\n",
    "phenofhy.load.field_list(\n",
    "    fields=[\n",
    "        \"participant.birth_month\",\n",
    "        \"participant.birth_year\",\n",
    "        \"participant.registration_month\",\n",
    "        \"participant.registration_year\",\n",
    "        \"participant.pid\",\n",
    "        \"questionnaire.birth_place_1_1\",\n",
    "        \"questionnaire.housing_people_1_1\",\n",
    "        \"questionnaire.housing_people_relate_1_m\",\n",
    "        # \"questionnaire.work_status_1_m\",\n",
    "        # \"questionnaire.work_status_2_m\"\n",
    "    ],\n",
    "    output_file=\"outputs/intermediate/questionnaire_diag_fields_metadata.csv\"\n",
    ")\n",
    "\n",
    "phenofhy.extract.fields(\n",
    "    input_file=\"outputs/intermediate/questionnaire_diag_fields_metadata.csv\",\n",
    "    output_file=\"outputs/raw/questionnaire_diag_fields_raw_values_query.sql\", \n",
    "    cohort_key=\"FULL_SAMPLE_ID\", \n",
    "    sql_only=True\n",
    ")\n",
    "\n",
    "raw_questionnaire_df = phenofhy.extract.sql_to_pandas(\n",
    "    \"outputs/raw/questionnaire_diag_fields_raw_values_query.sql\"\n",
    ")\n",
    "\n",
    "pheno_df = phenofhy.process.participant_fields(raw_questionnaire_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questionnaire_df = phenofhy.process.questionnaire_fields(pheno_df, derive='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Birth place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questionnaire_df['questionnaire.birth_place_1_1'].value_counts()/ questionnaire_df['questionnaire.birth_place_1_1'].notnull().sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questionnaire_df['questionnaire.birth_place_1_1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Housing relatednesss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add live alone as a category to housing_people_relate_1_m\n",
    "live_alone_mask = questionnaire_df[\"questionnaire.housing_people_1_1\"] == 1\n",
    "trait = \"questionnaire.housing_people_relate_1_m\"\n",
    "questionnaire_df.loc[live_alone_mask, trait] = \"Live alone\"\n",
    "\n",
    "# compute counts\n",
    "res = phenofhy.calculate.summary(questionnaire_df, \n",
    "                                  traits=['questionnaire.housing_people_relate_1_m'], \n",
    "                                  granularity=\"categorical\")\n",
    "res['categorical']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Household size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Column for convenience\n",
    "col = \"questionnaire.housing_people_1_1\"\n",
    "\n",
    "# Define bins and labels\n",
    "bins = [0, 1, 2, 3, 4, 10, np.inf]   # upper bounds\n",
    "labels = [\"1\", \"2\", \"3\", \"4\", \"5-9\", \"10+\"]\n",
    "\n",
    "# Create bucket column\n",
    "questionnaire_df[\"household_bucket\"] = pd.cut(\n",
    "    questionnaire_df[col],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    right=True,         # 1 goes to '1', 2 to '2', etc.\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Compute percentages\n",
    "pct_df = (\n",
    "    questionnaire_df[\"household_bucket\"]\n",
    "    .value_counts(normalize=True, dropna=True)\n",
    "    .sort_index()\n",
    "    .mul(100)\n",
    "    .round(2)\n",
    "    .rename(\"percentage\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(pct_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine v1 and v2\n",
    "map_work_status = {\n",
    "    -3: \"Prefer not to answer\",\n",
    "    -7: \"None of the above\",\n",
    "    -5: \"Unemployed\",     # from version 2\n",
    "     5: \"Unemployed\",     # from version 1\n",
    "     1: \"In paid employment or self-employed\",\n",
    "     2: \"Retired\",\n",
    "     3: \"Looking after home/family\",\n",
    "     4: \"Unable to work\",\n",
    "     6: \"Doing unpaid/voluntary work\",\n",
    "     7: \"Student\",\n",
    "     8: \"On paid leave\",\n",
    "     9: \"Unpaid carer\",\n",
    "}\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def map_cell(x):\n",
    "    # safe NA check\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "\n",
    "    # if multi-response array/list\n",
    "    if isinstance(x, (list, tuple, set, np.ndarray)):\n",
    "        vals = list(x)\n",
    "    else:\n",
    "        vals = [x]\n",
    "\n",
    "    out = []\n",
    "    for v in vals:\n",
    "        # convert v to int if possible\n",
    "        try:\n",
    "            v_key = int(v)\n",
    "        except Exception:\n",
    "            v_key = v\n",
    "\n",
    "        out.append(map_work_status.get(v_key, str(v)))\n",
    "\n",
    "    # dedupe while preserving order\n",
    "    return list(dict.fromkeys(out))\n",
    "\n",
    "\n",
    "v1 = \"questionnaire.work_status_1_m\"\n",
    "v2 = \"questionnaire.work_status_2_m\"\n",
    "\n",
    "df = questionnaire_df.copy()\n",
    "\n",
    "df[\"_v1_list\"] = df[v1].apply(map_cell)\n",
    "df[\"_v2_list\"] = df[v2].apply(map_cell)\n",
    "\n",
    "# Combined multi-response list (union of both)\n",
    "df[\"work_status_combined\"] = df.apply(\n",
    "    lambda r: list(dict.fromkeys(r[\"_v1_list\"] + r[\"_v2_list\"])),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = phenofhy.calculate.summary(\n",
    "    df,\n",
    "    traits=[\"work_status_combined\"],\n",
    "    granularity=\"category\"\n",
    ")\n",
    "\n",
    "res[\"categorical\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
