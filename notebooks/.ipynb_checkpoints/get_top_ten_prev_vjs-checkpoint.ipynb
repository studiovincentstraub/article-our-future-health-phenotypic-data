{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction and prevalence calculation of self-reported health conditions (OFH)\n",
    "\n",
    "## Purpose\n",
    "This notebook extracts selected self-reported health condition fields from the Our Future Health (OFH) baseline questionnaire, processes participant-level responses, and computes prevalence estimates for the most common conditions in the cohort.\n",
    "\n",
    "## Outputs\n",
    "- `outputs/intermediate/questionnaire_diag_fields_metadata.csv`  \n",
    "  Metadata describing questionnaire diagnosis fields included in the analysis.\n",
    "- `outputs/raw/questionnaire_diag_fields_raw_values_query.sql`  \n",
    "  SQL query used to extract raw questionnaire responses.\n",
    "- `outputs/intermediate/questionnaire_diag_sub_fields_metadata.csv`  \n",
    "  Metadata for sub-fields associated with selected questionnaire diagnoses.\n",
    "- `outputs/raw/questionnaire_diag_sub_fields_raw_values_query.sql`  \n",
    "  SQL query used to extract raw sub-field responses.\n",
    "- In-memory pandas DataFrames containing processed questionnaire responses and prevalence estimates used for downstream tabulation.\n",
    "\n",
    "## Relationship to manuscript\n",
    "Results from this notebook are used to populate **Supplementary Table 5** (*Most common self-reported health conditions in Our Future Health, the UK Biobank, and Health Survey England 2021*).\n",
    "\n",
    "## Data and access notes\n",
    "Analyses use restricted Our Future Health data accessed within the OFH Trusted Research Environment under approved study permissions. Outputs are limited to aggregated, non-disclosive summary statistics in accordance with OFH Safe Output policies.\n",
    "\n",
    "## Notes\n",
    "Prevalence estimates are calculated using participant-level questionnaire data without derivation of composite phenotypes. Only fields explicitly listed in the input metadata files are included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import dxpy\n",
    "import shlex\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import phenofhy\n",
    "import phenofhy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Phenotype Analysis\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"128\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"table_s5_questionnaire_diag_fields.csv\",\n",
    "    \"table_s5_other_codes.csv\",\n",
    "]\n",
    "\n",
    "phenofhy.utils.download_files([\n",
    "    (str(phenofhy.utils.find_latest_dx_file_id(f)), f\"inputs/{f}\")\n",
    "    for f in files\n",
    "])\n",
    "\n",
    "pheno_df = pd.read_csv(f'./inputs/{files[0]}')\n",
    "codes_df = pd.read_csv(f'./inputs/{files[1]}')\n",
    "\n",
    "traits = (pheno_df.iloc[:9,:][\"entity\"] + \".\" + pheno_df.iloc[:9,:][\"coding_name\"]).tolist()\n",
    "sub_traits = (pheno_df.iloc[9:,:][\"entity\"] + \".\" + pheno_df.iloc[9:,:][\"coding_name\"]).tolist()\n",
    "\n",
    "metadata_dfs = phenofhy.load.metadata()\n",
    "\n",
    "phenofhy.load.field_list(\n",
    "    fields=traits,\n",
    "    output_file=\"outputs/intermediate/questionnaire_diag_fields_metadata.csv\",\n",
    ")\n",
    "\n",
    "phenofhy.extract.fields(\n",
    "    input_file=\"outputs/intermediate/questionnaire_diag_fields_metadata.csv\",\n",
    "    output_file=\"outputs/raw/questionnaire_diag_fields_raw_values_query.sql\", \n",
    "    cohort_key=\"FULL_SAMPLE_ID\", \n",
    "    sql_only=True\n",
    ")\n",
    "\n",
    "raw_questionnaire_df = phenofhy.extract.sql_to_pandas(\n",
    "    \"outputs/raw/questionnaire_diag_fields_raw_values_query.sql\"\n",
    ")\n",
    "\n",
    "questionnaire_df = phenofhy.process.participant_fields(raw_questionnaire_df)\n",
    "questionnaire_df = phenofhy.process.questionnaire_fields(questionnaire_df, derive=False)\n",
    "\n",
    "phenofhy.load.field_list(\n",
    "    fields=sub_traits,\n",
    "    output_file=\"outputs/intermediate/questionnaire_diag_sub_fields_metadata.csv\",\n",
    ")\n",
    "\n",
    "phenofhy.extract.fields(\n",
    "    input_file=\"outputs/intermediate/questionnaire_diag_sub_fields_metadata.csv\",\n",
    "    output_file=\"outputs/raw/questionnaire_diag_sub_fields_raw_values_query.sql\", \n",
    "    cohort_key=\"FULL_SAMPLE_ID\", \n",
    "    sql_only=True\n",
    ")\n",
    "\n",
    "raw_sub_questionnaire_df = phenofhy.extract.sql_to_pandas(\n",
    "    \"outputs/raw/questionnaire_diag_sub_fields_raw_values_query.sql\"\n",
    ")\n",
    "\n",
    "sub_questionnaire_df = phenofhy.process.participant_fields(raw_sub_questionnaire_df)\n",
    "sub_questionnaire_df = phenofhy.process.questionnaire_fields(sub_questionnaire_df, derive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute prevalence for top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questionnaire_prev = phenofhy.calculate.prevalence(\n",
    "    df=questionnaire_df,\n",
    "    codings=metadata_dfs[\"codings\"],\n",
    "    traits=traits\n",
    ")\n",
    "\n",
    "questionnaire_prev.loc[\n",
    "    questionnaire_prev['coding_name'].isin(traits[-2:])][['meaning', 'count', 'prevalence']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute prevalnce of Other/None of the above counts per diagnosis category for top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_questionnaire_prev = phenofhy.calculate.prevalence(\n",
    "    df=sub_questionnaire_df,\n",
    "    codings=metadata_dfs[\"codings\"],\n",
    "    traits=sub_traits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# 1) select rows whose meaning is \"None of the above\" OR contains \"other\" (case-insensitive)\n",
    "pattern = r'\\bnone of the above\\b|\\bother\\b|\\banother\\b'\n",
    "mask = sub_questionnaire_prev['meaning'].astype(str).str.contains(pattern, case=False, regex=True)\n",
    "\n",
    "# 2) group by trait (and coding_name) and sum counts; take denominator (assumed constant per group)\n",
    "summary = (\n",
    "    sub_questionnaire_prev.loc[mask]\n",
    "    .groupby(['trait', 'coding_name'], as_index=False)\n",
    "    .agg(count=('count', 'sum'),\n",
    "         denominator=('denominator', 'first'))\n",
    ")\n",
    "\n",
    "# 3) recompute prevalence from summed counts\n",
    "summary['prevalence'] = summary['count'] / summary['denominator']\n",
    "\n",
    "# result\n",
    "summary[['trait','count', 'prevalence']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
